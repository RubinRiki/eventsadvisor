from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from server.core.deps import get_db
from server.core.config import settings
from server.models.ai import ChatRequest, ChatResponse

import requests
import logging
from server.api.rag_service import build_event_index, retrieve_relevant_events

router = APIRouter(prefix="/ai", tags=["ai"])
logger = logging.getLogger(__name__)


def _build_messages(body: ChatRequest) -> list[dict]:
    messages: list[dict] = []
    if body.history:
        messages.extend({"role": m.role, "content": m.content} for m in body.history)
    if body.question:
        messages.append({"role": "user", "content": body.question})
    return messages


@router.post("/ask", response_model=ChatResponse)
def ask_ai(body: ChatRequest, db: Session = Depends(get_db)):
    print(f"ğŸš€ /ai/ask × ×§×¨× ×¢× ×©××œ×”: {body.question}")

    model_name = settings.AI_MODEL
    url = f"{settings.OLLAMA_URL.rstrip('/')}/api/chat"
    print(f"ğŸ“¤ URL ×©×œ Ollama: {url}")
    print(f"âš™ï¸ ××•×“×œ × ×‘×—×¨: {model_name}")

    # ---------- ×©×œ×‘ RAG ----------
    try:
        print("ğŸ“¦ ×‘×•× ×™× ××™× ×“×§×¡ ××”Ö¾DB...")
        docs = build_event_index(db)
        print(f"âœ… ×˜×¢× ×• {len(docs)} ××™×¨×•×¢×™× ××”Ö¾DB")
        relevant = retrieve_relevant_events(body.question, docs, k=3)
        print(f"âœ¨ ×ª×•×¦××•×ª ×¨×œ×•×•× ×˜×™×•×ª ××”Ö¾RAG: {relevant}")
        context_text = "\n\n".join(doc["text"] for doc in relevant)
    except Exception as e:
        logger.error(f"RAG failed: {e}")
        print(f"âŒ ×©×’×™××” ×‘×‘× ×™×™×ª ××™× ×“×§×¡/RAG: {e}")
        context_text = ""

    # ××•×¡×™×¤×™× context ×œ×”×•×“×¢×•×ª
    messages = _build_messages(body)
    if context_text:
        system_msg = f"×”× ×” × ×ª×•× ×™ ××™×¨×•×¢×™× ×¨×œ×•×•× ×˜×™×™× ××”Ö¾DB:\n{context_text}"
        messages.insert(0, {"role": "system", "content": system_msg})
        print(f"ğŸ“ ×”×•×¡×¤× ×• context ×œ××•×“×œ: {system_msg}")

    payload = {"model": model_name, "messages": messages, "stream": False}
    print(f"ğŸ“¦ Payload × ×©×œ×— ×œÖ¾Ollama: {payload}")

    # ---------- ×§×¨×™××” ×œÖ¾Ollama ----------
    try:
        r = requests.post(url, json=payload, timeout=settings.AI_TIMEOUT)
        r.raise_for_status()
    except requests.RequestException as e:
        logger.error(f"AI service unavailable: {e}")
        print(f"âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ ×œÖ¾Ollama: {e}")
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="AI service unavailable",
        )

    try:
        data = r.json() or {}
        print(f"ğŸ“¥ ×ª×©×•×‘×” ×’×•×œ××™×ª ××”Ö¾Ollama: {data}")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¤×¢× ×•×— JSON ××”Ö¾Ollama: {e}")
        raise HTTPException(status_code=502, detail="invalid AI JSON response")

    # × × ×¡×” ×œ×”×•×¦×™× ×ª×©×•×‘×”
    answer = ""
    if isinstance(data.get("message"), dict):
        answer = data["message"].get("content", "")
    if not answer and "response" in data:
        answer = data.get("response", "")
    if not answer:
        print(f"âŒ AI ×”×—×–×™×¨ ×ª×©×•×‘×” ×œ× ×ª×§×™× ×”: {data}")
        raise HTTPException(status_code=502, detail="invalid AI response")

    print(f"âœ… ×ª×©×•×‘×” ×¡×•×¤×™×ª ×œ×¦'××˜: {answer}")
    return ChatResponse(answer=answer, used_model=model_name, from_cache=False)
